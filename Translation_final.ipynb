{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Course: DEEP LEARNING (20PEEC601LD)**\n",
        "\n",
        "**T. Y. (E&TC) (A. Y. 2022-23) (Sem. II)**\n",
        "\n",
        "\n",
        "**Professor :  Dr Ashwini Deshpande**\n",
        " \n",
        "\n",
        " \n",
        "\n",
        "3155, C22020111156- Mihika Kothawade\n",
        "\n",
        "3162, C22020111163- Shreeya Mahajan\n",
        "\n",
        "3167, C22020111168- Vaishnavi Mane\n",
        "\n",
        "3168, C22020111169- Aishwarya Anil Menon\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "BATCH: DL-2 \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "FLkIlc9nBxwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation and Importing Libraries"
      ],
      "metadata": {
        "id": "3sJPajll8s_p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eMMJssyxQ-J"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C24JKO7LxP3O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "import pickle\n",
        "from numpy import random\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,LayerNormalization,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input,MultiHeadAttention,Embedding,TextVectorization)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from keras.nlp.metrics import Bleu\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "LdwxalEeyUX5",
        "outputId": "fc66c657-a6bb-49e6-dd5e-5582c25eb3fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKg0HdsrYA0S"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgU1Z8fcOSW_"
      },
      "source": [
        "## Data Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hwhov2uvDdo",
        "outputId": "b666651e-9150-46b4-9e6f-4116cef4497d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-21 08:31:57--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7420323 (7.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.08M  5.97MB/s    in 1.2s    \n",
            "\n",
            "2023-04-21 08:31:59 (5.97 MB/s) - ‘fra-eng.zip’ saved [7420323/7420323]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ufBPwn8_ax",
        "outputId": "3918d713-ae3b-47d6-d188-c9940227ede0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBHsJDpiYDs7"
      },
      "source": [
        "## Kaggle Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lako-uhxy-n",
        "outputId": "64b6004b-9ce9-48f8-a7e9-7aafe30eca11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d dhruvildave/en-fr-translation-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B44hfX_vxzA-",
        "outputId": "11dac328-291e-4800-cf85-5cb4d587fc5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/en-fr-translation-dataset.zip, /content/en-fr-translation-dataset.zip.zip or /content/en-fr-translation-dataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/en-fr-translation-dataset.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXcOEWp2L7U9"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.experimental.CsvDataset(\n",
        "  \"/content/dataset/en-fr.csv\",\n",
        "  [\n",
        "    tf.string,\n",
        "    tf.string\n",
        "  ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omyb2Dq_YHbT"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywC7WnoIJeXl"
      },
      "outputs": [],
      "source": [
        "text_dataset=tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlcJxz6cJeb_"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE=20000\n",
        "ENGLISH_SEQUENCE_LENGTH=64\n",
        "FRENCH_SEQUENCE_LENGTH=64\n",
        "EMBEDDING_DIM=256\n",
        "BATCH_SIZE=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TePer9o-JeeR"
      },
      "outputs": [],
      "source": [
        "english_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unGn0zqEJegg"
      },
      "outputs": [],
      "source": [
        "french_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNK3uewuQTjY"
      },
      "outputs": [],
      "source": [
        "def selector(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZDH8xn7Q12e"
      },
      "outputs": [],
      "source": [
        "split_dataset=text_dataset.map(selector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fcSDED_2c-z"
      },
      "outputs": [],
      "source": [
        "def separator(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktN95hiN2pgU"
      },
      "outputs": [],
      "source": [
        "init_dataset=text_dataset.map(separator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQkSkpd1tils",
        "outputId": "8bf5cf99-fc97-43e3-ebd8-6f010af6b808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_usEDYiOJeil"
      },
      "outputs": [],
      "source": [
        "english_training_data=init_dataset.map(lambda x,y:x)### input x,y and output x\n",
        "english_vectorize_layer.adapt(english_training_data)#### adapt the vectorize_layer to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl7pxJprJek2"
      },
      "outputs": [],
      "source": [
        "french_training_data=init_dataset.map(lambda x,y:y)### input x,y and output y\n",
        "french_vectorize_layer.adapt(french_training_data)#### adapt the vectorize_layer to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yVIMxvTJemt"
      },
      "outputs": [],
      "source": [
        "def vectorizer(inputs,output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op5UqhS14HHz",
        "outputId": "6e5d9c13-7e6e-4705-b563-376b2110db3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "split_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI9-GPpVJepF"
      },
      "outputs": [],
      "source": [
        "dataset=split_dataset.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_6Xtks8wPk5",
        "outputId": "36bf6193-2688-4a0e-82a6-0d56c9e73d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM9aenklufpC",
        "outputId": "2b90def8-0013-43d9-91ac-77be5c0cf0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[104,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(1):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOpSsko7TiKd",
        "outputId": "cd421a62-7389-427f-dcca-901e45cb755f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WE0s6p9TiM9"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTkF_Qu54QB5",
        "outputId": "75bde7ec-aaa1-4c98-ccd4-5851e564a68d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5JXDdrNtwRj"
      },
      "outputs": [],
      "source": [
        "NUM_BATCHES=int(200000/BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQvg18V5TiO7"
      },
      "outputs": [],
      "source": [
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfCmn1DzTiRp",
        "outputId": "7f321f9f-a943-4363-d7ad-467cb6597608"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku7L4gZJXgYY"
      },
      "outputs": [],
      "source": [
        "#score=tf.einsum('ijk,ibk->ijb',query,key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBVM2EB0Xh97"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXZLSM5pkS3w"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1_5MCwq0ARk"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(model_size,SEQUENCE_LENGTH):\n",
        "  output=[]\n",
        "  for pos in range(SEQUENCE_LENGTH):\n",
        "    PE=np.zeros((model_size))\n",
        "    for i in range(model_size):\n",
        "      if i%2==0:\n",
        "        PE[i]=np.sin(pos/(10000**(i/model_size)))\n",
        "      else:\n",
        "        PE[i]=np.cos(pos/(10000**((i-1)/model_size)))\n",
        "    output.append(tf.expand_dims(PE,axis=0))\n",
        "  out=tf.concat(output,axis=0)\n",
        "  out=tf.expand_dims(out,axis=0)\n",
        "  return tf.cast(out,dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD4gK6uLxY8B",
        "outputId": "7f37520c-1eeb-4ece-bb53-ad93cd987942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 64, 256)\n"
          ]
        }
      ],
      "source": [
        "print(positional_encoding(256,64).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM8tUhJ9G0tH"
      },
      "outputs": [],
      "source": [
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocab_size, embed_dim,):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.token_embeddings=Embedding(\n",
        "        input_dim=vocab_size, output_dim=embed_dim)\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions=positional_encoding(\n",
        "        self.embed_dim,self.sequence_length)\n",
        "    return embedded_tokens + embedded_positions\n",
        "    \n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    return tf.math.not_equal(inputs, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr0o-QcgD4xS",
        "outputId": "f98611b9-ca0c-4a5e-fea2-317b9a3c5bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 256)\n"
          ]
        }
      ],
      "source": [
        "test_input=tf.constant([[  2, 112,   10,   12,  5,   0,   0,   0,]])\n",
        "\n",
        "emb=Embeddings(8,20000,256)\n",
        "emb_out=emb(test_input)\n",
        "print(emb_out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoZ59gSaom6P",
        "outputId": "f507b64d-ba11-4eb9-c652-960baa643bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[0 0 0 0 0 1 1 1]\n",
            "  [0 0 0 0 0 1 1 1]\n",
            "  [0 0 0 0 0 1 1 1]\n",
            "  [0 0 0 0 0 1 1 1]\n",
            "  [0 0 0 0 0 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]\n",
            "  [1 1 1 1 1 1 1 1]]], shape=(1, 8, 8), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "mask=emb.compute_mask(test_input)\n",
        "mask1 = mask[:, :, tf.newaxis]\n",
        "mask2 = mask[:,tf.newaxis, :]\n",
        "padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n",
        "print(1-padding_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaDKmgJgklY_"
      },
      "source": [
        "## Custom MultiHeadAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIRfhrVINS39"
      },
      "outputs": [],
      "source": [
        "class CustomSelfAttention(Layer):\n",
        "  def __init__(self,model_size):\n",
        "    super(CustomSelfAttention,self).__init__()\n",
        "    self.model_size=model_size\n",
        "  def call(self,query,key,value,masking):\n",
        "    ######## compute scores\n",
        "    score=tf.matmul(query,key,transpose_b=True)\n",
        "    ######## scaling\n",
        "    score/=tf.math.sqrt(tf.cast(self.model_size,tf.float32))\n",
        "    ######## masking\n",
        "    masking=tf.cast(masking,dtype=tf.float32)\n",
        "    score+=(1.-masking)*-1e10\n",
        "    ######## attention_weights\n",
        "    attention=tf.nn.softmax(score,axis=-1)*masking\n",
        "    ######## output\n",
        "    head=tf.matmul(attention,value)\n",
        "    return head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSqZtns6YdHP",
        "outputId": "8bbe7fd5-d66d-413c-f308-773cbeb68bfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8, 256), dtype=float32, numpy=\n",
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "attention=CustomSelfAttention(256)\n",
        "attention(tf.ones([1,8,256]),tf.ones([1,8,256]),tf.ones([1,8,256]),padding_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Unruv2vNS6g"
      },
      "outputs": [],
      "source": [
        "class CustomMultiHeadAttention(Layer):\n",
        "  def __init__(self,num_heads,key_dim):\n",
        "    super(CustomMultiHeadAttention,self).__init__()\n",
        "    \n",
        "    self.num_heads=num_heads\n",
        "    self.dense_q=[Dense(key_dim) for _ in range(num_heads)]\n",
        "    self.dense_k=[Dense(key_dim) for _ in range(num_heads)]\n",
        "    self.dense_v=[Dense(key_dim) for _ in range(num_heads)]\n",
        "    self.dense_o=Dense(key_dim)\n",
        "    self.self_attention=CustomSelfAttention(key_dim)\n",
        "    \n",
        "  def call(self,query,key,value,attention_mask):\n",
        "    heads=[]\n",
        "    \n",
        "    for i in range(self.num_heads):\n",
        "        head=self.self_attention(self.dense_q[i](query),self.dense_k[i](key),\n",
        "                                self.dense_v[i](value),attention_mask)\n",
        "        heads.append(head)\n",
        "    heads=tf.concat(heads,axis=2)\n",
        "    heads=self.dense_o(heads)\n",
        "    return heads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-Y512TzkOKQ"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jvze09LsnAw"
      },
      "outputs": [],
      "source": [
        "#?tf.keras.layers.MultiHeadAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5lTjZBE6M4Q"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads,):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim,\n",
        "        )\n",
        "        self.dense_proj=tf.keras.Sequential(\n",
        "            [Dense(dense_dim, activation=\"relu\"),Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = LayerNormalization()\n",
        "        self.layernorm_2 = LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "      if mask is not None:\n",
        "        mask1 = mask[:, :, tf.newaxis]\n",
        "        mask2 = mask[:,tf.newaxis, :]\n",
        "        padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n",
        "\n",
        "      attention_output = self.attention(\n",
        "          query=inputs, key=inputs,value=inputs,attention_mask=padding_mask\n",
        "      )\n",
        "      \n",
        "      proj_input = self.layernorm_1(inputs + attention_output)\n",
        "      proj_output = self.dense_proj(proj_input)\n",
        "      return self.layernorm_2(proj_input + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOgozN6bu3hv",
        "outputId": "e0b73486-fb6d-4fc6-8ee6-ebf9aa3651b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 256)\n"
          ]
        }
      ],
      "source": [
        "encoder_outputs = TransformerEncoder(256,2048,2)(emb_out)\n",
        "print(encoder_outputs.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDTmNxkmkctq"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdHTwxmfHWZW"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(Layer):\n",
        "  def __init__(self, embed_dim, latent_dim, num_heads,):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.attention_1=MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.attention_2=MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.dense_proj = tf.keras.Sequential(\n",
        "        [Dense(latent_dim, activation=\"relu\"),Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1=LayerNormalization()\n",
        "    self.layernorm_2=LayerNormalization()\n",
        "    self.layernorm_3=LayerNormalization()\n",
        "    self.supports_masking = True\n",
        "  def call(self, inputs, encoder_outputs, mask=None):\n",
        "    \n",
        "    if mask is not None:\n",
        "      mask1 = mask[:, :, tf.newaxis]\n",
        "      mask2 = mask[:,tf.newaxis, :]\n",
        "      padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n",
        "      causal_mask=tf.linalg.band_part(tf.ones([tf.shape(inputs)[0],tf.shape(inputs)[1],\n",
        "                                               tf.shape(inputs)[1]],dtype=tf.int32),-1,0)\n",
        "      combined_mask=tf.minimum(padding_mask,causal_mask)\n",
        "\n",
        "    attention_output_1 = self.attention_1(\n",
        "        query=inputs,key=inputs,value=inputs,\n",
        "        attention_mask=causal_mask,\n",
        "        \n",
        "    )\n",
        "    out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "    attention_output_2,scores= self.attention_2(\n",
        "        query=out_1,key=encoder_outputs,value=encoder_outputs,\n",
        "        attention_mask=combined_mask,\n",
        "        return_attention_scores=True\n",
        "    )\n",
        "    out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "    proj_output = self.dense_proj(out_2)\n",
        "    return self.layernorm_3(out_2 + proj_output),scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ0i7k60eDGk",
        "outputId": "a039aedd-31b9-4b77-d368-0726a3565716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 256)\n",
            "(1, 4, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "decoder_outputs,scores = TransformerDecoder(256,2048,4)(emb_out,encoder_outputs)\n",
        "print(decoder_outputs.shape)\n",
        "print(scores.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SPdfBx8ke-Z"
      },
      "source": [
        "## Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsT7pvXfzh_E"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM=128\n",
        "D_FF=1024\n",
        "NUM_HEADS=8\n",
        "NUM_LAYERS=1\n",
        "NUM_EPOCHS=10\n",
        "attention_scores={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7_vJmd8HWbu",
        "outputId": "7e60176c-b14c-47ca-bc74-7955aaed3c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embeddings_1 (Embeddings)      (None, 64, 128)      2560000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embeddings_2 (Embeddings)      (None, 64, 128)      2560000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Transfo  (None, 64, 128)     791296      ['embeddings_1[0][0]']           \n",
            " rmerEncoder)                                                                                     \n",
            "                                                                                                  \n",
            " transformer_decoder_1 (Transfo  ((None, 64, 128),   1319040     ['embeddings_2[0][0]',           \n",
            " rmerDecoder)                    (None, 8, 64, 64))               'transformer_encoder_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 64, 20000)    2580000     ['transformer_decoder_1[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,810,336\n",
            "Trainable params: 9,810,336\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n",
        "x = Embeddings(ENGLISH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(encoder_inputs)\n",
        "\n",
        "for _ in range(NUM_LAYERS):\n",
        "  x=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n",
        "encoder_outputs=x\n",
        "\n",
        "decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n",
        "\n",
        "x = Embeddings(FRENCH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(decoder_inputs)\n",
        "for i in range(NUM_LAYERS):\n",
        "  x,scores=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs)\n",
        "  attention_scores[f'decoder_layer{i+1}_block2']=scores\n",
        "decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "\n",
        "attention_score_model= tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], attention_scores, name=\"atttention_score_model\"\n",
        ")\n",
        "transformer = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")\n",
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urO3w5e971Hp"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBb_YQFGaztF"
      },
      "outputs": [],
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='bleu_score'):\n",
        "        super(BLEU,self).__init__()\n",
        "        self.bleu_score=0\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred,-1)\n",
        "      self.bleu_score=0\n",
        "      for i,j in zip(y_pred,y_true):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches=0\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if word==j[q]:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "\n",
        "        self.bleu_score+=total_matches/total_words\n",
        "        \n",
        "    def result(self):\n",
        "        return self.bleu_score/BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAKCOX98HWd9"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(2e-4),\n",
        "    metrics=['acc'],)\n",
        "    #run_eagerly=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "z0p0nxCMmkq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2529VjOrVuGe",
        "outputId": "46b3cd90-f771-445f-cf9b-00690c73267c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2812/2812 [==============================] - 424s 146ms/step - loss: 4.0696 - acc: 0.4163 - val_loss: 3.3776 - val_acc: 0.4468\n",
            "Epoch 2/10\n",
            "2812/2812 [==============================] - 354s 126ms/step - loss: 2.2689 - acc: 0.6031 - val_loss: 2.6464 - val_acc: 0.5448\n",
            "Epoch 3/10\n",
            "2812/2812 [==============================] - 350s 124ms/step - loss: 1.6555 - acc: 0.6749 - val_loss: 2.3441 - val_acc: 0.5800\n",
            "Epoch 4/10\n",
            " 584/2812 [=====>........................] - ETA: 3:54 - loss: 1.3838 - acc: 0.7102"
          ]
        }
      ],
      "source": [
        "history=transformer.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset.take(300),\n",
        "    epochs=NUM_EPOCHS, \n",
        "    callbacks=[checkpoint, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj3wLwSW7EMb"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nHgZZwQ_Gl8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(transformer, f)"
      ],
      "metadata": {
        "id": "RsYCsPRAznlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWJfUFU9VrQx"
      },
      "outputs": [],
      "source": [
        "transformer.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i1ajAymaDoF"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5vMnTM62Cx_"
      },
      "outputs": [],
      "source": [
        "index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiWzshkMKfQg"
      },
      "outputs": [],
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken'\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "    output=transformer.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
        "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    current_word=index_to_word[french_word_index]\n",
        "    if current_word=='endtoken':\n",
        "      break\n",
        "    shifted_target+=' '+current_word\n",
        "  return shifted_target[11:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RYy2vtxKfS7"
      },
      "outputs": [],
      "source": [
        "translator('What makes you think that it is not true?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1BQFbrdKfVZ"
      },
      "outputs": [],
      "source": [
        "translator('Have you ever watched soccer under the rain?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je_d1YvagbZO"
      },
      "outputs": [],
      "source": [
        "translator(\"what's your name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWoISRgEVM_J"
      },
      "outputs": [],
      "source": [
        "translator('Great trees do not grow with ease, the stronger the winds, the stronger the trees')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtuuqPkgVNB0"
      },
      "outputs": [],
      "source": [
        "translator('My hotel told me to call you. ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "levLKdrZerPj"
      },
      "outputs": [],
      "source": [
        "translator('His French is improving little by little')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFEqsF4AerR3"
      },
      "outputs": [],
      "source": [
        "translator('I love to write')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_27Gta23erUa"
      },
      "outputs": [],
      "source": [
        "translator('Perhaps she will come tomorrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1FizaA6erXE"
      },
      "outputs": [],
      "source": [
        "translator('Tom has never heard Mary sing.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fekzqiwGerZd"
      },
      "outputs": [],
      "source": [
        "translator('She handed him the money')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lVMdXSi9d2Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "5-dufWz8d2k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken je lai fait très bien'\n",
        "\n",
        "  tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "  attention_weights=attention_score_model.predict([tokenized_english_sentence,\n",
        "                                                   tokenized_shifted_target])\n",
        "    \n",
        "  return attention_weights\n",
        "\n",
        "out=visualize('I did it very well')\n"
      ],
      "metadata": {
        "id": "0-d86MTK3gJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out['decoder_layer1_block2'][0].shape)"
      ],
      "metadata": {
        "id": "4G2b6i3APj7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,12))\n",
        "\n",
        "for i in range(NUM_HEADS):\n",
        "  ax = plt.subplot(2,4, i+1)\n",
        "  \n",
        "  plt.imshow(out['decoder_layer1_block2'][0][i][0:10,0:10])\n",
        "  plt.title(\"Attention Scores for head:->\"+str(i+1))"
      ],
      "metadata": {
        "id": "dhg9F90xPkA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44qa8hxykZEG"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self,transformer):\n",
        "    super(Transformer,self).__init__()\n",
        "    self.transformer=transformer\n",
        "    \n",
        "  def compile(self,loss_fn,optimizer):\n",
        "    super(Transformer,self).compile()\n",
        "    self.optimizer=optimizer\n",
        "    self.loss_fn=loss_fn\n",
        "    self.loss_metric=tf.keras.metrics.Mean(name='loss')\n",
        "    \n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.loss_metric,]\n",
        "\n",
        "  def train_step(self,x_y):\n",
        "    inputs,target=x_y\n",
        "    encoder_input=inputs['input_1']\n",
        "    shifted_target=inputs['input_2']\n",
        "\n",
        "    with tf.GradientTape() as recorder:\n",
        "\n",
        "      output,_=self.transformer([encoder_input,shifted_target])\n",
        "      loss=self.loss_fn(target,output)\n",
        "      \n",
        "    partial_derivatives = recorder.gradient(loss,self.transformer.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(partial_derivatives, self.transformer.trainable_weights))\n",
        "\n",
        "    self.loss_metric.update_state(loss)\n",
        "    \n",
        "    return {'loss':self.loss_metric.result()}\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Extraction form Audio Files"
      ],
      "metadata": {
        "id": "XfKiezXV7Qli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0NDwAlkb7VUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git   -q"
      ],
      "metadata": {
        "id": "elr9f9St8Kiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the whisper library\n",
        "import whisper"
      ],
      "metadata": {
        "id": "pjj5g27H8LzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"medium\") #769M Parameter  \n",
        "#loading the model\n",
        "#the larger the size of the parameters caught the more accurate the results would be"
      ],
      "metadata": {
        "id": "BgfANpQS8ORa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Used to play the audio\n",
        "from IPython.display import Audio, display"
      ],
      "metadata": {
        "id": "3X4uWgqQ8Rsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Audio('/content/drive/MyDrive/DL Project Try/english_text.mp3', autoplay=True))"
      ],
      "metadata": {
        "id": "Lngxb4b08S52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#speech to text transcription\n",
        "result = model.transcribe(\"/content/drive/MyDrive/DL Project Try/english_text.mp3\")\n",
        "the_data = result[\"text\"]\n",
        "print(the_data)"
      ],
      "metadata": {
        "id": "DZNJKYW38Uok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Extraction from Images"
      ],
      "metadata": {
        "id": "pXHm-gri8Xr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "vVXNfWCP8c5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import easyocr\n",
        "from pylab import rcParams\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "-c3DpZf58eT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 8, 16"
      ],
      "metadata": {
        "id": "ex74jkk28lvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "KxQHo3DV8fsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"/content/drive/MyDrive/DL Project Try/english_text_image.jpeg\")"
      ],
      "metadata": {
        "id": "vupaccBa8g2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = reader.readtext('/content/drive/MyDrive/DL Project Try/english_text_image.jpeg')\n",
        "output"
      ],
      "metadata": {
        "id": "MvF-ZLRH8iIk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3sJPajll8s_p",
        "cKg0HdsrYA0S",
        "WgU1Z8fcOSW_",
        "RBHsJDpiYDs7",
        "omyb2Dq_YHbT",
        "nBVM2EB0Xh97",
        "UXZLSM5pkS3w",
        "QaDKmgJgklY_",
        "S-Y512TzkOKQ",
        "jDTmNxkmkctq",
        "1SPdfBx8ke-Z",
        "4i1ajAymaDoF",
        "5-dufWz8d2k_",
        "XfKiezXV7Qli",
        "pXHm-gri8Xr5"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}